{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb0f3b39",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-03-06T12:16:55.809887Z",
     "iopub.status.busy": "2025-03-06T12:16:55.809568Z",
     "iopub.status.idle": "2025-03-06T12:16:55.887257Z",
     "shell.execute_reply": "2025-03-06T12:16:55.886027Z"
    },
    "papermill": {
     "duration": 0.08215,
     "end_time": "2025-03-06T12:16:55.888575",
     "exception": true,
     "start_time": "2025-03-06T12:16:55.806425",
     "status": "failed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'iteration_utilities'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-4b5ee63addfe>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0miteration_utilities\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mflatten\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'iteration_utilities'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from iteration_utilities import flatten\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "from scipy.stats import mode\n",
    "\n",
    "class RecGym_DATA(Dataset):\n",
    "    def __init__(self, root_path, window_size, overlap_size, transform=None):\n",
    "        \"\"\"\n",
    "        root_path : Root directory of the data set\n",
    "        window_size : Size of the window in seconds\n",
    "        overlap_size : Size of the overlap in seconds\n",
    "        transform : Optional transform to be applied on a sample\n",
    "        \"\"\"\n",
    "        self.root_path = root_path\n",
    "        self.window_size = window_size\n",
    "        self.overlap_size = overlap_size\n",
    "        self.transform = transform\n",
    "        self.used_cols = [\"A_x\", \"A_y\", \"A_z\", \"G_x\", \"G_y\", \"G_z\", \"C_1\", \"Workout\", \"Subject\", \"Session\"]\n",
    "        self.label_map = {\n",
    "            \"Adductor\": 1, \"ArmCurl\": 2, \"BenchPress\": 3, \"LegCurl\": 4, \"LegPress\": 5, \"Null\": 6, \n",
    "            \"Riding\": 7, \"RopeSkipping\": 8, \"Running\": 9, \"Squat\": 10, \"StairClimber\": 11, \"Walking\": 12\n",
    "        }\n",
    "        self.labelToId = {v: k for v, k in self.label_map.items()}\n",
    "        self.data_x, self.data_y, self.subjects, self.sessions = self.load_all_the_data()\n",
    "\n",
    "    def load_all_the_data(self):\n",
    "        print(\" ----------------------- load all the data -------------------\")\n",
    "        df_all = pd.read_csv(os.path.join(self.root_path, \"RecGym.csv\"))\n",
    "        df_all = df_all[self.used_cols]\n",
    "        df_all.dropna(inplace=True)\n",
    "        df_all[\"Workout\"] = df_all[\"Workout\"].map(self.labelToId)\n",
    "        data_y = df_all[\"Workout\"].values\n",
    "        data_x = df_all.drop(columns=[\"Workout\", \"Subject\", \"Session\"]).values\n",
    "        subjects = df_all[\"Subject\"].values\n",
    "        sessions = df_all[\"Session\"].values\n",
    "\n",
    "        # Segment the data into windows\n",
    "        window_size_samples = int(self.window_size * 20)  # 20Hz sampling rate\n",
    "        overlap_size_samples = int(self.overlap_size * 20)\n",
    "        step_size = window_size_samples - overlap_size_samples\n",
    "\n",
    "        segmented_data_x = []\n",
    "        segmented_data_y = []\n",
    "        segmented_subjects = []\n",
    "        segmented_sessions = []\n",
    "\n",
    "        for start in range(0, len(data_x) - window_size_samples + 1, step_size):\n",
    "            end = start + window_size_samples\n",
    "            window_x = data_x[start:end]\n",
    "            window_y = data_y[start:end]\n",
    "            window_subjects = subjects[start:end]\n",
    "            window_sessions = sessions[start:end]\n",
    "            segmented_data_x.append(window_x)\n",
    "            segmented_data_y.append(mode(window_y)[0])  # Most common label in the window\n",
    "            segmented_subjects.append(mode(window_subjects)[0])  # Most common subject in the window\n",
    "            segmented_sessions.append(mode(window_sessions)[0])  # Most common session in the window\n",
    "\n",
    "\n",
    "        self.data_x = np.array(segmented_data_x)\n",
    "        self.data_y = np.array(segmented_data_y)\n",
    "        self.subjects = np.array(segmented_subjects)\n",
    "        self.sessions = np.array(segmented_sessions)\n",
    "\n",
    "        print(self.data_x.shape)\n",
    "        print(self.data_y.shape)\n",
    "        return self.data_x, self.data_y, self.subjects, self.sessions\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_x)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.data_x[idx]\n",
    "        label = self.data_y[idx]\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "        return sample, label\n",
    "\n",
    "def load_data(root_path, batch_size, window_size, overlap_size, training_strategy, fold):\n",
    "    dataset = RecGym_DATA(root_path, window_size, overlap_size)\n",
    "    \n",
    "    if training_strategy == \"LOUO\":\n",
    "        if fold < 1 or fold > 10:\n",
    "            raise ValueError(\"Fold number for LOUO must be between 1 and 10.\")\n",
    "        train_idx = np.where(dataset.subjects != fold)[0]\n",
    "        test_idx = np.where(dataset.subjects == fold)[0]\n",
    "    elif training_strategy == \"LOSO\":\n",
    "        if fold < 1 or fold > 5:\n",
    "            raise ValueError(\"Fold number for LOSO must be between 1 and 5.\")\n",
    "        train_idx = np.where(dataset.sessions != fold)[0]\n",
    "        test_idx = np.where(dataset.sessions == fold)[0]\n",
    "    else:\n",
    "        raise ValueError(\"Invalid training strategy. Choose either 'LOUO' or 'LOSO'.\")\n",
    "\n",
    "    train_x, train_y = dataset.data_x[train_idx], dataset.data_y[train_idx]\n",
    "    test_x, test_y = dataset.data_x[test_idx], dataset.data_y[test_idx]\n",
    "\n",
    "    train_dataset = CustomDataset(train_x, train_y, dataset.transform)\n",
    "    test_dataset = CustomDataset(test_x, test_y, dataset.transform)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "\n",
    "    return train_loader, test_loader\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data_x, data_y, transform=None):\n",
    "        self.data_x = data_x\n",
    "        self.data_y = data_y\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_x)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.data_x[idx]\n",
    "        label = self.data_y[idx]\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "        return sample, label\n",
    "\n",
    "def main():\n",
    "    root_path = \"datasets\"\n",
    "    batch_size = 64\n",
    "    window_size = 4  # Window size in seconds\n",
    "    overlap_size = 2  # Overlap size in seconds\n",
    "    training_strategy = \"LOUO\"  # Training strategy: \"LOUO\"(Leave-One-User-Out) or \"LOSO\"(Leave-One-Session-Out)\n",
    "    fold = 1  # Fold number for cross-validation  (1-10 for LOUO, 1-5 for LOSO)\n",
    "\n",
    "    train_loader, test_loader = load_data(root_path, batch_size, window_size, overlap_size, training_strategy, fold)\n",
    "\n",
    "    for i, (samples, labels) in enumerate(train_loader):\n",
    "        print(f\"Train Batch {i+1}\")\n",
    "        print(\"Samples:\", samples)\n",
    "        print(\"Labels:\", labels)\n",
    "        if i == 0:  # Print only the first batch for brevity\n",
    "            break\n",
    "\n",
    "    for i, (samples, labels) in enumerate(test_loader):\n",
    "        print(f\"Test Batch {i+1}\")\n",
    "        print(\"Samples:\", samples)\n",
    "        print(\"Labels:\", labels)\n",
    "        if i == 0:  # Print only the first batch for brevity\n",
    "            break\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 689811,
     "sourceId": 10733530,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30886,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 2.732166,
   "end_time": "2025-03-06T12:16:56.306980",
   "environment_variables": {},
   "exception": true,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-03-06T12:16:53.574814",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
